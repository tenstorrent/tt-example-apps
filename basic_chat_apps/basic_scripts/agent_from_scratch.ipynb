{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f8d019e-8c4c-4d3c-94f2-211e057c9665",
   "metadata": {},
   "source": [
    "### AI Agent from Scratch on Tenstorrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123f422c-73f9-43e3-98f8-d5aedf25fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC\n",
    "#\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "import json\n",
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1064cad7-c9ac-4fc7-b8dd-451acb0ca34f",
   "metadata": {},
   "source": [
    "### Custom function to fetch current weather conditions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95fdd8a7-d200-49f8-9480-9b01a62ffc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather(location):\n",
    "    params = {\n",
    "        \"q\": location,\n",
    "        \"key\": os.environ[\"WEATHER_API_KEY\"]\n",
    "    }\n",
    "    base_url = \"http://api.weatherapi.com/v1/current.json\"\n",
    "\n",
    "    res = requests.get(base_url, params=params)\n",
    "    data = res.json()\n",
    "    current_data = data['current']\n",
    "\n",
    "    temp_string = f\"{current_data['temp_f']} 째F\"\n",
    "    \n",
    "    condition_string = current_data['condition']['text']\n",
    "    location_string = f\"{data['location']['name']}, {data['location']['region']}\"\n",
    "\n",
    "    return f\"Weather in {location_string}: {temp_string}, {condition_string}.\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff6b63-f707-46f1-a0d8-62dbd8a5b573",
   "metadata": {},
   "source": [
    "### Set Tenstorrent endpoint URL and create client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b670f6-6bac-4e62-a8e6-eaec63e60c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_base_url = os.environ[\"TT_BASE_URL\"]  # \"https://<...>.koyeb.app/v1\"\n",
    "\n",
    "client = OpenAI(base_url=tt_base_url, api_key=\"null\")\n",
    "models = client.models.list()\n",
    "model_id = models.data[0].id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21f705b-5c9c-46f3-af70-84d599fffc66",
   "metadata": {},
   "source": [
    "## Overview\n",
    "1. User submits query to LLM\n",
    "2. LLM determines if a tool call is necessary.  If so, it will formulate a function call with parameters\n",
    "    - i.e. If the query is `\"What's the weather in Chicago?\"` the LLM should return a tool call of `{'location': 'Chicago'}`\n",
    "3. We use the JSON function call to run the actual `fetch_weather` function with the LLM's provided arguments.\n",
    "4. The tool call and context is passed back to the LLM to generate a final response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a9947-2ec8-4011-bebf-455db189a77e",
   "metadata": {},
   "source": [
    "### 1. Define tools in OpenAI function calling schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad63859-b0e6-42c1-b6c8-d0514cb132d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"fetch_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\", \n",
    "                    \"description\": \"The city, region, or place, like 'Austin', 'New York City', or 'Barcelona'\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bba045-9361-452c-8da4-e8e2b90def45",
   "metadata": {},
   "source": [
    "### 2. Create user prompt and system message\n",
    "The system message will instruct the LLM on how to act and respond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b0d8a16-6c55-4436-b8ac-0427a81c1dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = {\n",
    "    \"role\": \"user\", \n",
    "    \"content\": \"I'm going to Anchorage, how should I dress?\"\n",
    "}\n",
    "\n",
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\":\n",
    "        \"\"\"\n",
    "        You are a helpful assistant that gives practical outfit recommendations based on the current weather conditions provided.\\n\n",
    "        When given details like temperature, rain, wind, and other weather factors, suggest appropriate clothing items and accessories for comfort.\\n\n",
    "        Keep your suggestions concise, relevant, and user-friendly.\\n\n",
    "        Example:\n",
    "        - \"It's cold and windy, wear a warm coat and a scarf.\"\n",
    "        - \"Expect rain, bring an umbrella and wear waterproof shoes.\"\n",
    "        You must repeat the weather data so the user knows the exact forecast.\n",
    "        \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42844e21-f103-43ea-a902-d16a5702c27a",
   "metadata": {},
   "source": [
    "### 3. Call completion to get tool call parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79c0b26f-4bc8-4e20-90db-a7ab5e783245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TOOL CALL] Parameters: {'location': 'Anchorage'}\n"
     ]
    }
   ],
   "source": [
    "tool_call_response = client.chat.completions.create(\n",
    "    model=model_id,\n",
    "    messages=[system_message, user_message],\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "tool_call = tool_call_response.choices[0].message.tool_calls[0]\n",
    "\n",
    "parameters = json.loads(tool_call.function.arguments)\n",
    "\n",
    "print(f\"[TOOL CALL] Parameters: {parameters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58deadc-9adf-4c6e-ad08-19ba8ebc689f",
   "metadata": {},
   "source": [
    "### 4. Run function with tool call parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c38ebc2b-9553-4b65-8f1f-e790a6df16d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TOOL CALL] Output: Weather in Anchorage, Alaska: 63.0 째F, Partly Cloudy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = fetch_weather(**parameters)\n",
    "\n",
    "print(f\"[TOOL CALL] Output: {context}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc99c4a7-77c3-4ed9-960b-6930b5050304",
   "metadata": {},
   "source": [
    "### 5. Give tool call and tool output back to model as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5aafbd8-704a-4671-ad91-aee86f77097c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': '\\n        You are a helpful assistant that gives practical outfit recommendations based on the current weather conditions provided.\\n\\n        When given details like temperature, rain, wind, and other weather factors, suggest appropriate clothing items and accessories for comfort.\\n\\n        Keep your suggestions concise, relevant, and user-friendly.\\n\\n        Example:\\n        - \"It\\'s cold and windy, wear a warm coat and a scarf.\"\\n        - \"Expect rain, bring an umbrella and wear waterproof shoes.\"\\n        You must repeat the weather data so the user knows the exact forecast.\\n        '}\n",
      "{'role': 'user', 'content': \"I'm going to Anchorage, how should I dress?\"}\n",
      "{'role': 'assistant', 'tool_calls': [{'id': 'chatcmpl-tool-4bbfc99e98c0434a92c66a8129c7e04c', 'type': 'function', 'function': {'name': 'fetch_weather', 'arguments': '{\"location\": \"Anchorage\"}'}}]}\n",
      "{'role': 'tool', 'tool_call_id': 'chatcmpl-tool-4bbfc99e98c0434a92c66a8129c7e04c', 'content': 'Weather in Anchorage, Alaska: 63.0 째F, Partly Cloudy.\\n'}\n"
     ]
    }
   ],
   "source": [
    "assistant_message = {\n",
    "    \"role\": \"assistant\",\n",
    "    \"tool_calls\": [{\n",
    "        \"id\": tool_call.id,\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": tool_call.function.name,\n",
    "            \"arguments\": tool_call.function.arguments\n",
    "        }\n",
    "    }]\n",
    "}\n",
    "\n",
    "tool_call_message = {\n",
    "    \"role\": \"tool\",\n",
    "    \"tool_call_id\": tool_call.id,\n",
    "    \"content\": context\n",
    "}\n",
    "\n",
    "messages = [system_message, user_message, assistant_message, tool_call_message]\n",
    "\n",
    "for message in messages:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a1a3c3-b02c-4736-8b18-a7fa6b17cca1",
   "metadata": {},
   "source": [
    "### 6. Run final chat completion for final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1252a04c-c765-4d7d-a152-a285b37f34e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's 63째F in Anchorage, Alaska, with partly cloudy conditions. To dress comfortably, I suggest wearing:\n",
      "\n",
      "- A light sweater or a fleece jacket for layering.\n",
      "- Comfortable jeans or trousers.\n",
      "- A pair of sturdy shoes or boots suitable for walking.\n",
      "- Consider bringing a lightweight rain jacket or poncho, as occasional rain showers are possible.\n",
      "\n",
      "Please check the latest forecast before your trip to ensure the most accurate information."
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=model_id,\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    delta = chunk.choices[0].delta.content or \"\"\n",
    "    print(delta, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
